{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "795747ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import os\n",
    "import configparser\n",
    "import boto3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d2d94b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read in initial data\n",
    "# data = json.load(open('init_spot_forecasts.json'))\n",
    "\n",
    "# # id name type submission_time deliver_time wfo\n",
    "# df = pd.DataFrame(data['hydra:member'])\n",
    "\n",
    "# df['wfo'] = [o['nativeSiteId'] for o in df['office']]\n",
    "# df['name'] = df['projectName']\n",
    "# df['type'] = [i['name'] for i in df['incident']]\n",
    "# df['submission_time'] = df['submittedAt']\n",
    "# df['deliver_time'] = df['deliverAt']\n",
    "\n",
    "# df = df[['id', 'name', 'type', 'submission_time', 'deliver_time', 'wfo']]\n",
    "\n",
    "# # just the offices we want\n",
    "# offices = [\"MTR\", \"STO\", \"HNX\", \"LOX\", \"SGX\", \"VEF\", \"REV\", \"MTR\", \"EKA\"]\n",
    "\n",
    "# df = df[[o in offices for o in df['wfo']]]\n",
    "\n",
    "# df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e5ba6204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the config \n",
    "cp = configparser.ConfigParser(interpolation=None)\n",
    "\n",
    "# read env file based on location\n",
    "if os.path.exists('../../.env'):  \n",
    "    cp.read('../../.env')  \n",
    "elif os.path.exists('/Users/emma.stiefel/.env'):\n",
    "    cp.read('/Users/emma.stiefel/.env')  \n",
    "else: # production\n",
    "    cp.read(\"/home/ec2-user/Projects/deploy-engine/.env\")\n",
    "\n",
    "os.environ[\"SFC_AWS_ACCESS_KEY_ID\"] = cp.get('aws', 's3_user')\n",
    "os.environ[\"SFC_AWS_SECRET_ACCESS_KEY\"] = cp.get('aws', 's3_pass')\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "sfc_bucket_string = 'sfc-project-files'\n",
    "sfc_client = boto3.client('s3',\n",
    "    aws_access_key_id=os.environ['SFC_AWS_ACCESS_KEY_ID'],\n",
    "    aws_secret_access_key=os.environ['SFC_AWS_SECRET_ACCESS_KEY']\n",
    ")\n",
    "\n",
    "# send message to slack\n",
    "webhook_url = \"https://hooks.slack.com/services/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\"\n",
    "def send_message(message):\n",
    "    # print(message)\n",
    "    message_dict = {\n",
    "        \"text\": message\n",
    "    }\n",
    "    r = requests.post(\n",
    "        webhook_url, \n",
    "        data=json.dumps(message_dict),\n",
    "        headers={'Content-Type': 'application/json'}\n",
    "        )\n",
    "        \n",
    "try:\n",
    "    # read in existing data\n",
    "    df = pd.read_json(\"https://files.sfchronicle.com/radar-ca-nws-spot-forecasts/spot_forecasts.json\")\n",
    "\n",
    "    # load in and process new data\n",
    "    url = 'https://spot.weather.gov/cms/api/1.0/requests?office.id=&isArchived=false'\n",
    "    r = requests.get(url)\n",
    "\n",
    "    new_df = pd.DataFrame(r.json())\n",
    "\n",
    "    new_df['wfo'] = [o['nativeSiteId'] for o in new_df['office']]\n",
    "    new_df['name'] = new_df['projectName']\n",
    "    new_df['type'] = [i['name'] for i in new_df['incident']]\n",
    "    new_df['submission_time'] = new_df['submittedAt']\n",
    "    new_df['deliver_time'] = new_df['deliverAt']\n",
    "\n",
    "    new_df = new_df[['id', 'name', 'type', 'submission_time', 'deliver_time', 'wfo']]\n",
    "\n",
    "    # just the offices we want\n",
    "    offices = [\"MTR\", \"STO\", \"HNX\", \"LOX\", \"SGX\", \"VEF\", \"REV\", \"MTR\", \"EKA\"]\n",
    "    new_df = new_df[[o in offices for o in new_df['wfo']]]\n",
    "\n",
    "    # find forecasts that are new, not in existing df\n",
    "    new_forecasts = new_df[[i not in list(df['id']) for i in new_df['id']]]\n",
    "        \n",
    "    # send alerts for each new forecast\n",
    "    tz = pytz.timezone('US/Pacific')\n",
    "    for i, r in new_forecasts.iterrows(): \n",
    "        # convert times\n",
    "        s = datetime.fromisoformat(r['submission_time'])\n",
    "        s = s.astimezone(tz)\n",
    "        s = s.strftime('%m/%d/%25 %I:%M%p')\n",
    "\n",
    "        d = datetime.fromisoformat(r['deliver_time'])\n",
    "        d = d.astimezone(tz)\n",
    "        d = d.strftime('%m/%d/%25 %I:%M%p')\n",
    "        send_message(f\"New spot forecast request\\nName: {r['name']}\\nType: {r['type']}\\nWFO: {r['wfo']}\\nSubmitted: {s}\\nDelivered: {d}\")\n",
    "\n",
    "    # save new df as old df\n",
    "    # new_df.to_csv('spot_forecasts.csv')\n",
    "    sfc_client.put_object(Body=new_df.to_json(), Bucket=sfc_bucket_string, Key=\"radar-ca-nws-spot-forecasts/spot_forecasts.json\")\n",
    "\n",
    "except Exception as E:\n",
    "    send_message(f'scraping ERROR {E}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radar-ca-nws-spot-forecasts-NCMntogg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
